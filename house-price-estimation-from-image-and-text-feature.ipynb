{"metadata":{"kernelspec":{"display_name":"tensorflow","language":"python","name":"tensorflow"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# House price estimation from image and text feature. Concatenate MLP(csv) and CNN(image) together.","metadata":{}},{"cell_type":"code","source":"# import the necessary packages\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import Adam\nimport pandas as pd\nimport numpy as np\nimport glob\nimport cv2\nimport os\nimport locale","metadata":{"execution":{"iopub.status.busy":"2022-09-06T11:37:50.446386Z","iopub.execute_input":"2022-09-06T11:37:50.446802Z","iopub.status.idle":"2022-09-06T11:37:50.453293Z","shell.execute_reply.started":"2022-09-06T11:37:50.446728Z","shell.execute_reply":"2022-09-06T11:37:50.452041Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        break\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-09-06T11:14:22.982075Z","iopub.execute_input":"2022-09-06T11:14:22.982695Z","iopub.status.idle":"2022-09-06T11:14:23.139575Z","shell.execute_reply.started":"2022-09-06T11:14:22.982642Z","shell.execute_reply":"2022-09-06T11:14:23.138400Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"dir_data = '/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/'\npaths_test = glob.glob(dir_data+ 'test/*.dicom')\npaths_train = glob.glob(dir_data+ 'train/*.dicom')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(images[0])\n","metadata":{"execution":{"iopub.status.busy":"2022-09-06T11:17:11.247346Z","iopub.execute_input":"2022-09-06T11:17:11.247656Z","iopub.status.idle":"2022-09-06T11:17:11.546791Z","shell.execute_reply.started":"2022-09-06T11:17:11.247602Z","shell.execute_reply":"2022-09-06T11:17:11.544927Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"inputPath = \"/kaggle/input/Houses Dataset/HousesInfo.txt\"\ndatasetPath = \"/kaggle/input/Houses Dataset/\"\n\ncols = [\"bedrooms\", \"bathrooms\", \"area\", \"zipcode\", \"price\"]\ndf = pd.read_csv(inputPath, sep=\" \", header=None, names=cols)\n\n\nzipcodes, counts = np.unique(df[\"zipcode\"], return_counts=True)\n\n# loop over each of the unique zip codes and their corresponding\n# count\nfor (zipcode, count) in zip(zipcodes, counts):\n    # the zip code counts for our housing dataset is *extremely*\n    # unbalanced (some only having 1 or 2 houses per zip code)\n    # so let's sanitize our data by removing any houses with less\n    # than 25 houses per zip code\n    if count < 25:\n        idxs = df[df[\"zipcode\"] == zipcode].index\n        df.drop(idxs, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T11:15:11.890124Z","iopub.execute_input":"2022-09-06T11:15:11.890446Z","iopub.status.idle":"2022-09-06T11:15:11.963356Z","shell.execute_reply.started":"2022-09-06T11:15:11.890387Z","shell.execute_reply":"2022-09-06T11:15:11.962512Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# initialize our images array (i.e., the house images themselves)\nimages = []\n\n# loop over the indexes of the houses\nfor i in df.index.values:\n    # find the four images for the house and sort the file paths,\n    # ensuring the four are always in the *same order*\n    basePath = os.path.sep.join([datasetPath, \"{}_*\".format(i + 1)])\n    housePaths = sorted(list(glob.glob(basePath)))\n    # initialize our list of input images along with the output image\n    # after *combining* the four input images\n    inputImages = []\n    outputImage = np.zeros((64, 64, 3), dtype=\"uint8\")\n\n    # loop over the input house paths\n    for housePath in housePaths:\n        # load the input image, resize it to be 32 32, and then\n        # update the list of input images\n        image = cv2.imread(housePath)\n        image = cv2.resize(image, (32, 32))\n        inputImages.append(image)\n\n    # tile the four input images in the output image such the first\n    # image goes in the top-right corner, the second image in the\n    # top-left corner, the third image in the bottom-right corner,\n    # and the final image in the bottom-left corner\n    outputImage[0:32, 0:32] = inputImages[0]\n    outputImage[0:32, 32:64] = inputImages[1]\n    outputImage[32:64, 32:64] = inputImages[2]\n    outputImage[32:64, 0:32] = inputImages[3]\n\n    # add the tiled image to our set of images the network will be\n    # trained on\n    images.append(outputImage)\nimages = np.array(images)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T11:15:16.138511Z","iopub.execute_input":"2022-09-06T11:15:16.138863Z","iopub.status.idle":"2022-09-06T11:15:34.241973Z","shell.execute_reply.started":"2022-09-06T11:15:16.138819Z","shell.execute_reply":"2022-09-06T11:15:34.241061Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"images = images / 255.0","metadata":{"execution":{"iopub.status.busy":"2022-09-06T11:17:29.418717Z","iopub.execute_input":"2022-09-06T11:17:29.419185Z","iopub.status.idle":"2022-09-06T11:17:29.469032Z","shell.execute_reply.started":"2022-09-06T11:17:29.419072Z","shell.execute_reply":"2022-09-06T11:17:29.468061Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# partition the data into training and testing splits using 75% of\n# the data for training and the remaining 25% for testing\nsplit = train_test_split(df, images, test_size=0.25, random_state=42)\n(trainAttrX, testAttrX, trainImagesX, testImagesX) = split","metadata":{"execution":{"iopub.status.busy":"2022-09-06T11:20:21.602371Z","iopub.execute_input":"2022-09-06T11:20:21.603091Z","iopub.status.idle":"2022-09-06T11:20:21.644554Z","shell.execute_reply.started":"2022-09-06T11:20:21.603035Z","shell.execute_reply":"2022-09-06T11:20:21.643539Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# find the largest house price in the training set and use it to\n# scale our house prices to the range [0, 1] (will lead to better\n# training and convergence)\nmaxPrice = trainAttrX[\"price\"].max()\ntrainY = trainAttrX[\"price\"] / maxPrice\ntestY = testAttrX[\"price\"] / maxPrice","metadata":{"execution":{"iopub.status.busy":"2022-09-06T11:19:56.545096Z","iopub.execute_input":"2022-09-06T11:19:56.545478Z","iopub.status.idle":"2022-09-06T11:19:56.553797Z","shell.execute_reply.started":"2022-09-06T11:19:56.545414Z","shell.execute_reply":"2022-09-06T11:19:56.552365Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# initialize the column names of the continuous data\ncontinuous = [\"bedrooms\", \"bathrooms\", \"area\"]\n\n# performin min-max scaling each continuous feature column to\n# the range [0, 1]\ncs = MinMaxScaler()\ntrainContinuous = cs.fit_transform(trainAttrX[continuous])\ntestContinuous = cs.transform(testAttrX[continuous])\n\n# one-hot encode the zip code categorical data (by definition of\n# one-hot encoing, all output features are now in the range [0, 1])\nzipBinarizer = LabelBinarizer().fit(df[\"zipcode\"])\ntrainCategorical = zipBinarizer.transform(trainAttrX[\"zipcode\"])\ntestCategorical = zipBinarizer.transform(testAttrX[\"zipcode\"])\n\n# construct our training and testing data points by concatenating\n# the categorical features with the continuous features\ntrainAttrX = np.hstack([trainCategorical, trainContinuous])\ntestAttrX = np.hstack([testCategorical, testContinuous])","metadata":{"execution":{"iopub.status.busy":"2022-09-06T11:20:23.663651Z","iopub.execute_input":"2022-09-06T11:20:23.664009Z","iopub.status.idle":"2022-09-06T11:20:23.681261Z","shell.execute_reply.started":"2022-09-06T11:20:23.663948Z","shell.execute_reply":"2022-09-06T11:20:23.680080Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"dim = trainAttrX.shape[1] #10\n\n# define our MLP network\nmlp = Sequential()\nmlp.add(Dense(8, input_dim=dim, activation=\"relu\"))\nmlp.add(Dense(4, activation=\"relu\"))\n","metadata":{"execution":{"iopub.status.busy":"2022-09-06T11:20:26.368028Z","iopub.execute_input":"2022-09-06T11:20:26.369056Z","iopub.status.idle":"2022-09-06T11:20:26.441362Z","shell.execute_reply.started":"2022-09-06T11:20:26.368987Z","shell.execute_reply":"2022-09-06T11:20:26.440155Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"from keras.models import Model, Input\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dense, Flatten, Dropout\nfrom keras.layers.normalization import BatchNormalization\n\nwidth, height, depth = 64, 64, 3\nfilters=(16, 32, 64)\n# initialize the input shape and channel dimension, assuming\n# TensorFlow/channels-last ordering\ninputShape = (height, width, depth)\nchanDim = -1\n\n# define the model input\ninputs = Input(shape=inputShape)\n\n# loop over the number of filters\nfor (i, f) in enumerate(filters):\n    # if this is the first CONV layer then set the input\n    # appropriately\n    if i == 0:\n        x = inputs\n\n    # CONV => RELU => BN => POOL\n    x = Conv2D(f, (3, 3), padding=\"same\")(x)\n    x = Activation(\"relu\")(x)\n    x = BatchNormalization(axis=chanDim)(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    \n# flatten the volume, then FC => RELU => BN => DROPOUT\nx = Flatten()(x)\nx = Dense(16)(x)\nx = Activation(\"relu\")(x)\nx = BatchNormalization(axis=chanDim)(x)\nx = Dropout(0.5)(x)\n\n# apply another FC layer, this one to match the number of nodes\n# coming out of the MLP\nx = Dense(4)(x)\nx = Activation(\"relu\")(x)\n\n# construct the CNN\ncnn = Model(inputs, x)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T11:20:28.726835Z","iopub.execute_input":"2022-09-06T11:20:28.727197Z","iopub.status.idle":"2022-09-06T11:20:29.352163Z","shell.execute_reply.started":"2022-09-06T11:20:28.727140Z","shell.execute_reply":"2022-09-06T11:20:29.350962Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"from keras.layers import concatenate\n# create the input to our final set of layers as the *output* of both\n# the MLP and CNN\ncombinedInput = concatenate([mlp.output, cnn.output])\n\n# our final FC layer head will have two dense layers, the final one\n# being our regression head\nx = Dense(4, activation=\"relu\")(combinedInput)\nx = Dense(1, activation=\"linear\")(x)\n\nmodel = Model(inputs=[mlp.input, cnn.input], outputs=x)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T11:20:35.044414Z","iopub.execute_input":"2022-09-06T11:20:35.044795Z","iopub.status.idle":"2022-09-06T11:20:35.086542Z","shell.execute_reply.started":"2022-09-06T11:20:35.044723Z","shell.execute_reply":"2022-09-06T11:20:35.085746Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"opt = Adam(lr=1e-3, decay=1e-3 / 200)\nmodel.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n ","metadata":{"execution":{"iopub.status.busy":"2022-09-06T11:20:38.043014Z","iopub.execute_input":"2022-09-06T11:20:38.043369Z","iopub.status.idle":"2022-09-06T11:20:38.087166Z","shell.execute_reply.started":"2022-09-06T11:20:38.043295Z","shell.execute_reply":"2022-09-06T11:20:38.086400Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# train the model\nmodel.fit(\n    [trainAttrX, trainImagesX], trainY,\n    validation_data=([testAttrX, testImagesX], testY),\n    epochs=200, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2022-09-06T11:20:40.851911Z","iopub.execute_input":"2022-09-06T11:20:40.852533Z","iopub.status.idle":"2022-09-06T11:28:40.239583Z","shell.execute_reply.started":"2022-09-06T11:20:40.852479Z","shell.execute_reply":"2022-09-06T11:28:40.238774Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# make predictions on the testing data\npreds = model.predict([testAttrX, testImagesX])","metadata":{"execution":{"iopub.status.busy":"2022-09-06T11:35:59.058742Z","iopub.execute_input":"2022-09-06T11:35:59.059098Z","iopub.status.idle":"2022-09-06T11:35:59.360595Z","shell.execute_reply.started":"2022-09-06T11:35:59.059052Z","shell.execute_reply":"2022-09-06T11:35:59.359602Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# plt.imshow(,lable=)\nfig, ax = plt.subplots(1)\nax.imshow(testImagesX[0], interpolation='nearest')\nax.text(5, 5, preds[0], bbox={'facecolor': 'white', 'pad': 10})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-06T11:52:51.343913Z","iopub.execute_input":"2022-09-06T11:52:51.344380Z","iopub.status.idle":"2022-09-06T11:52:51.504001Z","shell.execute_reply.started":"2022-09-06T11:52:51.344309Z","shell.execute_reply":"2022-09-06T11:52:51.503073Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"# compute the difference between the *predicted* house prices and the\n# *actual* house prices, then compute the percentage difference and\n# the absolute percentage difference\ndiff = preds.flatten() - testY\npercentDiff = (diff / testY) * 100\nabsPercentDiff = np.abs(percentDiff)\n \n# compute the mean and standard deviation of the absolute percentage\n# difference\nmean = np.mean(absPercentDiff)\nstd = np.std(absPercentDiff)\n \n# finally, show some statistics on our model\n\nlocale.setlocale(locale.LC_ALL, \"en_US.UTF-8\")\nprint(\"[INFO] avg. house price: {}, std house price: {}\".format(\n    locale.currency(df[\"price\"].mean(), grouping=True),\n    locale.currency(df[\"price\"].std(), grouping=True)))\nprint(\"[INFO] mean: {:.2f}%, std: {:.2f}%\".format(mean, std))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}